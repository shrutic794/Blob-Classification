# -*- coding: utf-8 -*-
"""DIVP Assignment ahhh myyy gaawdd.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FXcSZoRdTpgaBzRkZp5ELCb5oUAROqQJ
"""

!pip install tensorflow

!git clone https://github.com/google-deepmind/multi_object_datasets.git

from multi_object_datasets import tetrominoes
import tensorflow as tf

# download this tfrecords from the cloud storage which is given in the github - justin
tf_records_path = '/content/tetrominoes_tetrominoes_train.tfrecords'
batch_size = 4

# Create the dataset
dataset = tetrominoes.dataset(tf_records_path)
batched_dataset = dataset.batch(batch_size)  # optional batching

# In TF 2.x, you can directly iterate over the dataset
iterator = iter(batched_dataset)
data = next(iterator)

# Print the data structure
print("Data keys:", data.keys())
print("Shapes:", {k: v.shape for k, v in data.items()})

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os

# Assuming 'data' contains your batch with 'image' and 'mask' tensors
# If needed, run this to get data:
# iterator = iter(batched_dataset)
# data = next(iterator)

# Create a directory to save the images
os.makedirs('output_images_tetra', exist_ok=True)
os.makedirs('output_masks_tetra', exist_ok=True)

# Convert and save images
for i in range(data['image'].shape[0]):  # Loop through the batch
    # Get single image and convert to numpy
    image = data['image'][i].numpy()

    # Make sure values are in valid range for PNG (0-255)
    if image.max() <= 1.0:  # If normalized to [0,1]
        image = (image * 255).astype(np.uint8)
    else:
        image = image.astype(np.uint8)

    # Save the image using TensorFlow's encode_png
    image_tensor = tf.convert_to_tensor(image)
    png_image = tf.io.encode_png(image_tensor)
    tf.io.write_file(f'output_images_tetra/image_{i}.png', png_image)

    # Get the corresponding masks
    # The mask is [batch_size, num_objects, height, width, channels]
    masks = data['mask'][i]  # This is [num_objects, height, width, channels]

    # Save each object mask separately
    for obj_idx in range(masks.shape[0]):
        mask = masks[obj_idx].numpy()

        # Ensure values are in valid range for PNG
        if mask.max() <= 1.0:  # If normalized to [0,1]
            mask = (mask * 255).astype(np.uint8)
        else:
            mask = mask.astype(np.uint8)

        # Save the mask using TensorFlow's encode_png
        mask_tensor = tf.convert_to_tensor(mask)
        png_mask = tf.io.encode_png(mask_tensor)
        tf.io.write_file(f'output_masks_tetra/image_{i}_object_{obj_idx}.png', png_mask)

print(f"Saved {data['image'].shape[0]} images and their corresponding masks")

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import measure, filters, segmentation
from sklearn.metrics import accuracy_score, jaccard_score
from scipy import ndimage

def try_multiple_segmentation_methods(image, ground_truth):
    """
    Try multiple segmentation methods and select the best one
    """
    best_accuracy = 0
    best_segmented = None
    best_method = ""

    # Make a copy of the original image
    img = image.copy()

    # Convert to grayscale if the image is colored
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()

    # Method 1: Adaptive thresholding with preprocessing
    preprocessed1 = cv2.GaussianBlur(gray, (5, 5), 0)
    preprocessed1 = cv2.equalizeHist(preprocessed1)
    binary1 = cv2.adaptiveThreshold(preprocessed1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY, 11, 2)
    kernel = np.ones((3, 3), np.uint8)
    segmented1 = cv2.morphologyEx(binary1, cv2.MORPH_OPEN, kernel, iterations=1)
    segmented1 = cv2.morphologyEx(segmented1, cv2.MORPH_CLOSE, kernel, iterations=2)
    accuracy1 = evaluate_segmentation(segmented1, ground_truth)

    # Method 2: Otsu thresholding with CLAHE preprocessing
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    preprocessed2 = cv2.GaussianBlur(gray, (5, 5), 0)
    preprocessed2 = clahe.apply(preprocessed2)
    _, binary2 = cv2.threshold(preprocessed2, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    kernel = np.ones((3, 3), np.uint8)
    segmented2 = cv2.morphologyEx(binary2, cv2.MORPH_OPEN, kernel, iterations=1)
    segmented2 = cv2.morphologyEx(segmented2, cv2.MORPH_CLOSE, kernel, iterations=2)
    accuracy2 = evaluate_segmentation(segmented2, ground_truth)

    # Method 3: Canny edge detection + contour filling
    preprocessed3 = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(preprocessed3, 100, 200)
    # Dilate edges to ensure closed contours
    dilated_edges = cv2.dilate(edges, kernel, iterations=1)
    # Find contours and fill them
    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    segmented3 = np.zeros_like(gray)
    cv2.drawContours(segmented3, contours, -1, 255, -1)
    accuracy3 = evaluate_segmentation(segmented3, ground_truth)

    # Method 4: Watershed algorithm
    preprocessed4 = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(preprocessed4, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Noise removal
    kernel = np.ones((3,3), np.uint8)
    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)

    # Sure background area
    sure_bg = cv2.dilate(opening, kernel, iterations=3)

    # Finding sure foreground area
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)

    # Finding unknown region
    sure_fg = np.uint8(sure_fg)
    unknown = cv2.subtract(sure_bg, sure_fg)

    # Marker labelling
    ret, markers = cv2.connectedComponents(sure_fg)
    markers = markers+1
    markers[unknown==255] = 0

    # Apply watershed if it's a color image
    if len(img.shape) == 3:
        markers = cv2.watershed(img, markers)
        segmented4 = np.zeros_like(gray)
        segmented4[markers > 1] = 255
    else:
        # If grayscale, use the threshold result
        segmented4 = thresh

    accuracy4 = evaluate_segmentation(segmented4, ground_truth)

    # Method 5: K-means clustering
    if len(img.shape) == 3:
        Z = img.reshape((-1,3))
    else:
        Z = gray.reshape((-1,1))
    Z = np.float32(Z)

    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
    K = 2  # Number of clusters (foreground and background)
    _, labels, centers = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)

    # Convert back to uint8
    centers = np.uint8(centers)
    res = centers[labels.flatten()]

    if len(img.shape) == 3:
        segmented5 = res.reshape((img.shape))
        # Convert to grayscale for evaluation
        segmented5 = cv2.cvtColor(segmented5, cv2.COLOR_BGR2GRAY)
    else:
        segmented5 = res.reshape((gray.shape))

    # Binarize the result
    _, segmented5 = cv2.threshold(segmented5, 127, 255, cv2.THRESH_BINARY)
    accuracy5 = evaluate_segmentation(segmented5, ground_truth)

    # Display results of all methods
    print(f"Method 1 (Adaptive Thresholding): {accuracy1:.2f}%")
    print(f"Method 2 (Otsu + CLAHE): {accuracy2:.2f}%")
    print(f"Method 3 (Canny + Contour Filling): {accuracy3:.2f}%")
    print(f"Method 4 (Watershed): {accuracy4:.2f}%")
    print(f"Method 5 (K-means): {accuracy5:.2f}%")

    # Find the best method
    methods = [
        (segmented1, accuracy1, "Adaptive Thresholding"),
        (segmented2, accuracy2, "Otsu + CLAHE"),
        (segmented3, accuracy3, "Canny + Contour Filling"),
        (segmented4, accuracy4, "Watershed"),
        (segmented5, accuracy5, "K-means")
    ]

    best_segmented, best_accuracy, best_method = max(methods, key=lambda x: x[1])
    print(f"\nBest method: {best_method} with accuracy: {best_accuracy:.2f}%")

    # Visualize all methods
    plt.figure(figsize=(15, 10))
    plt.subplot(231), plt.imshow(gray, cmap='gray'), plt.title('Original')
    plt.subplot(232), plt.imshow(segmented1, cmap='gray'), plt.title(f'Adaptive: {accuracy1:.2f}%')
    plt.subplot(233), plt.imshow(segmented2, cmap='gray'), plt.title(f'Otsu+CLAHE: {accuracy2:.2f}%')
    plt.subplot(234), plt.imshow(segmented3, cmap='gray'), plt.title(f'Canny: {accuracy3:.2f}%')
    plt.subplot(235), plt.imshow(segmented4, cmap='gray'), plt.title(f'Watershed: {accuracy4:.2f}%')
    plt.subplot(236), plt.imshow(segmented5, cmap='gray'), plt.title(f'K-means: {accuracy5:.2f}%')
    plt.tight_layout()
    plt.show()

    return best_segmented, best_accuracy, best_method

def evaluate_segmentation(segmented_image, ground_truth):
    """
    Calculate the percentage of correctly segmented pixels and IoU
    """
    # Make sure both images have the same size
    if segmented_image.shape != ground_truth.shape:
        ground_truth = cv2.resize(ground_truth, (segmented_image.shape[1], segmented_image.shape[0]))

    # Binarize the ground truth if it's not already binary
    if ground_truth.max() > 1:
        _, ground_truth_binary = cv2.threshold(ground_truth, 127, 1, cv2.THRESH_BINARY)
    else:
        ground_truth_binary = ground_truth.copy()

    # Normalize the segmented image to 0-1
    segmented_binary = segmented_image.copy()
    if segmented_binary.max() > 1:
        segmented_binary = (segmented_binary / 255).astype(np.uint8)

    # Calculate accuracy (percentage of correctly segmented pixels)
    total_pixels = segmented_binary.size
    correct_pixels = np.sum(segmented_binary == ground_truth_binary)
    accuracy = (correct_pixels / total_pixels) * 100

    return accuracy

def perform_enhanced_blob_analysis(segmented_image):
    """
    Perform enhanced blob analysis to identify features
    """
    # Convert segmented image to binary if needed
    if segmented_image.max() > 1:
        _, binary = cv2.threshold(segmented_image, 127, 255, cv2.THRESH_BINARY)
    else:
        binary = segmented_image * 255

    # Label connected components
    labeled_image = measure.label(binary)

    # Measure properties of labeled regions
    props = measure.regionprops(labeled_image)

    # Filter blobs by size (remove very small ones)
    min_area = 50  # Adjust based on your image scale
    filtered_props = [prop for prop in props if prop.area > min_area]

    # Extract advanced features for each blob
    features = []
    for i, prop in enumerate(filtered_props):
        # Basic shape features
        blob_features = {
            'area': prop.area,
            'perimeter': prop.perimeter,
            'eccentricity': prop.eccentricity,
            'solidity': prop.solidity,
            'extent': prop.extent,
            'orientation': prop.orientation,
            'major_axis_length': prop.major_axis_length,
            'minor_axis_length': prop.minor_axis_length,
            'aspect_ratio': prop.major_axis_length / prop.minor_axis_length if prop.minor_axis_length > 0 else 0,
            'centroid': prop.centroid,
            'convex_area': prop.convex_area,
            'equivalent_diameter': prop.equivalent_diameter,
            'euler_number': prop.euler_number  # Number of objects minus number of holes
        }

        # Calculate circularity: 4π*area/perimeter²
        if prop.perimeter > 0:
            blob_features['circularity'] = 4 * np.pi * prop.area / (prop.perimeter ** 2)
        else:
            blob_features['circularity'] = 0

        # Calculate compactness: sqrt(4*area/π) / major_axis_length
        if prop.major_axis_length > 0:
            blob_features['compactness'] = np.sqrt(4 * prop.area / np.pi) / prop.major_axis_length
        else:
            blob_features['compactness'] = 0

        features.append(blob_features)

    # Regenerate a labeled image with only the filtered blobs
    filtered_labeled_image = np.zeros_like(labeled_image)
    for i, prop in enumerate(filtered_props):
        filtered_labeled_image[labeled_image == prop.label] = i + 1

    return features, filtered_labeled_image

def analyze_feature_importance(features):
    """
    Analyze which features are most important for discriminating between blobs
    """
    if len(features) <= 1:
        print("Not enough blobs for comparative analysis")
        return {}

    # Calculate variance for each feature
    feature_stats = {}
    for key in features[0].keys():
        if key != 'centroid':  # Skip centroid which is a tuple
            values = [blob[key] for blob in features]
            feature_stats[key] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'variance': np.var(values),
                'min': np.min(values),
                'max': np.max(values),
                'range': np.max(values) - np.min(values),
                'coefficient_of_variation': np.std(values) / np.mean(values) if np.mean(values) != 0 else 0
            }

    # Sort by coefficient of variation (std/mean) to find most discriminative features
    sorted_features = sorted(
        feature_stats.items(),
        key=lambda x: x[1]['coefficient_of_variation'],
        reverse=True
    )

    return sorted_features

def main():
    # Load the image and ground truth mask
    # Replace with your own image paths
    image_path = '/content/output_images_tetra/image_0.png'
    mask_path = '/content/output_masks_tetra/image_0_object_0.png'

    # Read the images
    image = cv2.imread(image_path)
    if image is not None:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    else:
        # Create dummy image for demonstration
        print("Image not found, creating dummy image")
        image = np.zeros((100, 100, 3), dtype=np.uint8)
        # Add some random shapes
        cv2.circle(image, (50, 50), 20, (255, 0, 0), -1)

    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    mask = cv2.bitwise_not(mask)
    if mask is None:
        # Create dummy mask for demonstration
        print("Mask not found, creating dummy mask")
        mask = np.zeros((100, 100), dtype=np.uint8)
        cv2.circle(mask, (50, 50), 20, 255, -1)

    # Try multiple segmentation methods and select the best one
    best_segmented, best_accuracy, best_method = try_multiple_segmentation_methods(image, mask)

    # Perform enhanced blob analysis on the best segmentation
    features, labeled_image = perform_enhanced_blob_analysis(best_segmented)

    # Print the extracted features
    print("\nEnhanced Blob Analysis Results:")
    for i, feature in enumerate(features):
        print(f"Blob {i+1}:")
        for key, value in feature.items():
            if key != 'centroid':
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: ({value[0]:.2f}, {value[1]:.2f})")

    # Analyze feature importance
    feature_importance = analyze_feature_importance(features)

    print("\nFeature Importance Analysis (sorted by discriminative power):")
    for feature, stats in feature_importance:
        print(f"  {feature}:")
        print(f"    - Coefficient of variation: {stats['coefficient_of_variation']:.4f}")
        print(f"    - Mean: {stats['mean']:.4f}")
        print(f"    - Std Dev: {stats['std']:.4f}")
        print(f"    - Range: {stats['range']:.4f}")

    # Visualize the final results
    plt.figure(figsize=(15, 5))

    plt.subplot(131)
    if len(image.shape) == 3:
        plt.imshow(image)
    else:
        plt.imshow(image, cmap='gray')
    plt.title('Original Image')

    plt.subplot(132)
    plt.imshow(mask, cmap='gray')
    plt.title('Ground Truth Mask')

    plt.subplot(133)
    plt.imshow(labeled_image, cmap='nipy_spectral')
    plt.title(f'Segmentation ({best_method})\nAccuracy: {best_accuracy:.2f}%')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import measure
from collections import deque
import time

def preprocess_image(image):
    """
    Preprocess the image for better segmentation
    """
    # Convert to grayscale if the image is colored
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()

    # Apply Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Apply adaptive thresholding
    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY_INV, 11, 2)

    # Apply morphological operations to clean up the binary image
    kernel = np.ones((3, 3), np.uint8)
    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)

    return opening

def recursive_grassfire(binary_image):
    """
    Implement the Recursive Grassfire algorithm for image segmentation
    """
    # Create a copy of the binary image for output
    output = np.zeros_like(binary_image)

    # Create a visited array to keep track of processed pixels
    visited = np.zeros_like(binary_image, dtype=bool)

    # Initialize label counter
    label = 1

    # Recursive function to propagate labels
    def burn(x, y, label):
        # Check if the pixel is out of bounds, already visited, or background
        if (x < 0 or x >= binary_image.shape[0] or
            y < 0 or y >= binary_image.shape[1] or
            visited[x, y] or binary_image[x, y] == 0):
            return

        # Mark the pixel as visited and assign the label
        visited[x, y] = True
        output[x, y] = label

        # Recursively visit 4-connected neighbors
        burn(x+1, y, label)  # Down
        burn(x-1, y, label)  # Up
        burn(x, y+1, label)  # Right
        burn(x, y-1, label)  # Left

    # Start time measurement
    start_time = time.time()

    # Iterate through all pixels
    height, width = binary_image.shape
    for x in range(height):
        for y in range(width):
            # If the pixel is foreground and not visited yet
            if binary_image[x, y] > 0 and not visited[x, y]:
                burn(x, y, label)
                label += 1

    # End time measurement
    end_time = time.time()

    print(f"Recursive Grassfire completed in {end_time - start_time:.4f} seconds")
    print(f"Found {label-1} connected components")

    return output

def sequential_grassfire(binary_image):
    """
    Implement the Sequential Grassfire algorithm for image segmentation
    """
    # Create a copy of the binary image for output
    output = np.zeros_like(binary_image)

    # Initialize label counter
    label = 1

    # Start time measurement
    start_time = time.time()

    # Iterate through all pixels
    height, width = binary_image.shape
    for x in range(height):
        for y in range(width):
            # If the pixel is foreground
            if binary_image[x, y] > 0:
                # Create a queue for BFS
                queue = deque([(x, y)])

                # Check if this pixel is already labeled
                if output[x, y] > 0:
                    continue

                # BFS to label all connected pixels
                while queue:
                    cur_x, cur_y = queue.popleft()

                    # Skip if already labeled or background
                    if output[cur_x, cur_y] > 0 or binary_image[cur_x, cur_y] == 0:
                        continue

                    # Label the current pixel
                    output[cur_x, cur_y] = label

                    # Add 4-connected neighbors to the queue
                    neighbors = [
                        (cur_x+1, cur_y),  # Down
                        (cur_x-1, cur_y),  # Up
                        (cur_x, cur_y+1),  # Right
                        (cur_x, cur_y-1)   # Left
                    ]

                    for nx, ny in neighbors:
                        if (0 <= nx < height and 0 <= ny < width and
                            binary_image[nx, ny] > 0 and output[nx, ny] == 0):
                            queue.append((nx, ny))

                # Increment label for next component
                label += 1

    # End time measurement
    end_time = time.time()

    print(f"Sequential Grassfire completed in {end_time - start_time:.4f} seconds")
    print(f"Found {label-1} connected components")

    return output

def evaluate_segmentation(segmented_image, ground_truth):
    """
    Calculate the percentage of correctly segmented pixels
    """
    # Make sure both images have the same size
    if segmented_image.shape != ground_truth.shape:
        ground_truth = cv2.resize(ground_truth, (segmented_image.shape[1], segmented_image.shape[0]))

    # Binarize the segmented image and ground truth
    if segmented_image.max() > 1:
        binary_segmented = (segmented_image > 0).astype(np.uint8)
    else:
        binary_segmented = segmented_image.astype(np.uint8)

    if ground_truth.max() > 1:
        binary_ground_truth = (ground_truth > 0).astype(np.uint8)
    else:
        binary_ground_truth = ground_truth.astype(np.uint8)

    # Calculate accuracy (percentage of correctly segmented pixels)
    total_pixels = binary_segmented.size
    correct_pixels = np.sum(binary_segmented == binary_ground_truth)
    accuracy = (correct_pixels / total_pixels) * 100

    # Calculate Jaccard index (IoU)
    intersection = np.logical_and(binary_segmented, binary_ground_truth).sum()
    union = np.logical_or(binary_segmented, binary_ground_truth).sum()
    iou = intersection / union if union != 0 else 0

    return accuracy, iou

def perform_blob_analysis(labeled_image):
    """
    Perform blob analysis to identify features
    """
    # Measure properties of labeled regions
    props = measure.regionprops(labeled_image)

    # Extract features for each blob
    features = []
    for prop in props:
        blob_features = {
            'area': prop.area,
            'perimeter': prop.perimeter,
            'eccentricity': prop.eccentricity,
            'solidity': prop.solidity,
            'extent': prop.extent,
            'orientation': prop.orientation,
            'major_axis_length': prop.major_axis_length,
            'minor_axis_length': prop.minor_axis_length,
            'aspect_ratio': prop.major_axis_length / prop.minor_axis_length if prop.minor_axis_length > 0 else 0,
            'centroid': prop.centroid,
            'convex_area': prop.convex_area,
            'equivalent_diameter': prop.equivalent_diameter,
            'euler_number': prop.euler_number,  # Number of objects minus number of holes
        }

        # Calculate circularity: 4π*area/perimeter²
        if prop.perimeter > 0:
            blob_features['circularity'] = 4 * np.pi * prop.area / (prop.perimeter ** 2)
        else:
            blob_features['circularity'] = 0

        features.append(blob_features)

    return features

def analyze_feature_importance(features):
    """
    Analyze which features are most discriminative for object classification
    """
    if len(features) <= 1:
        print("Not enough blobs to analyze feature importance")
        return []

    # Calculate statistics for each feature
    feature_stats = {}
    for key in features[0].keys():
        if key != 'centroid':
            values = [blob[key] for blob in features]
            feature_stats[key] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'variance': np.var(values),
                'min': np.min(values),
                'max': np.max(values),
                'range': np.max(values) - np.min(values),
                'coefficient_of_variation': np.std(values) / np.mean(values) if np.mean(values) != 0 else 0
            }

    # Sort features by coefficient of variation (higher is more discriminative)
    sorted_features = sorted(
        feature_stats.items(),
        key=lambda x: x[1]['coefficient_of_variation'],
        reverse=True
    )

    return sorted_features

def main():
    # Load the image and ground truth mask
    # Replace with your own image paths
    image_path = '/content/output_images_tetra/image_0.png'
    mask_path = '/content/output_masks_tetra/image_0_object_0.png'

    # Read the images
    image = cv2.imread(image_path)
    if image is not None:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    else:
        # Create a dummy image for demonstration
        print("Image not found, creating a dummy image")
        image = np.zeros((100, 100, 3), dtype=np.uint8)
        # Create some shapes
        cv2.rectangle(image, (20, 20), (40, 40), (255, 0, 0), -1)
        cv2.circle(image, (70, 70), 15, (0, 255, 0), -1)

    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    # mask = cv2.bitwise_not(mask)

    if mask is None:
        # Create a dummy mask for demonstration
        print("Mask not found, creating a dummy mask")
        mask = np.zeros((100, 100), dtype=np.uint8)
        cv2.rectangle(mask, (20, 20), (40, 40), 255, -1)
        cv2.circle(mask, (70, 70), 15, 255, -1)

    # Preprocess the image
    preprocessed = preprocess_image(image)

    # Run both grassfire algorithms
    print("\nRunning Recursive Grassfire algorithm...")
    recursive_result = recursive_grassfire(preprocessed)

    print("\nRunning Sequential Grassfire algorithm...")
    sequential_result = sequential_grassfire(preprocessed)

    # Evaluate segmentation results
    rec_accuracy, rec_iou = evaluate_segmentation(recursive_result, mask)
    seq_accuracy, seq_iou = evaluate_segmentation(sequential_result, mask)

    print(f"\nRecursive Grassfire Results:")
    print(f"- Accuracy: {rec_accuracy:.2f}%")
    print(f"- IoU (Jaccard Index): {rec_iou:.4f}")

    print(f"\nSequential Grassfire Results:")
    print(f"- Accuracy: {seq_accuracy:.2f}%")
    print(f"- IoU (Jaccard Index): {seq_iou:.4f}")

    # Choose the best method
    if rec_accuracy > seq_accuracy:
        print("\nRecursive Grassfire performed better.")
        best_result = recursive_result
        best_accuracy = rec_accuracy
        best_iou = rec_iou
        best_method = "Recursive Grassfire"
    else:
        print("\nSequential Grassfire performed better.")
        best_result = sequential_result
        best_accuracy = seq_accuracy
        best_iou = seq_iou
        best_method = "Sequential Grassfire"

    # Perform blob analysis on the best result
    # Convert to labeled image if needed
    if best_result.max() > 1:
        labeled_image = best_result
    else:
        labeled_image = measure.label(best_result)

    features = perform_blob_analysis(labeled_image)

    # Print detailed features for each blob
    print("\nBlob Analysis Results:")
    for i, feature in enumerate(features):
        print(f"Blob {i+1}:")
        for key, value in feature.items():
            if key != 'centroid':
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: ({value[0]:.2f}, {value[1]:.2f})")

    # Analyze feature importance
    important_features = analyze_feature_importance(features)

    print("\nFeature Importance Analysis (most discriminative features):")
    for feature, stats in important_features[:5]:  # Top 5 most important features
        print(f"  {feature}:")
        print(f"    - Coefficient of variation: {stats['coefficient_of_variation']:.4f}")
        print(f"    - Mean: {stats['mean']:.4f}")
        print(f"    - Std Dev: {stats['std']:.4f}")
        print(f"    - Range: {stats['range']:.4f}")

    # Visualize results
    plt.figure(figsize=(15, 10))

    plt.subplot(231)
    if len(image.shape) == 3:
        plt.imshow(image)
    else:
        plt.imshow(image, cmap='gray')
    plt.title('Original Image')

    plt.subplot(232)
    plt.imshow(preprocessed, cmap='gray')
    plt.title('Preprocessed Image')

    plt.subplot(233)
    plt.imshow(mask, cmap='gray')
    plt.title('Ground Truth Mask')

    plt.subplot(234)
    plt.imshow(recursive_result, cmap='nipy_spectral')
    plt.title(f'Recursive Grassfire\nAccuracy: {rec_accuracy:.2f}%')

    plt.subplot(235)
    plt.imshow(sequential_result, cmap='nipy_spectral')
    plt.title(f'Sequential Grassfire\nAccuracy: {seq_accuracy:.2f}%')

    plt.subplot(236)
    plt.imshow(labeled_image, cmap='nipy_spectral')
    plt.title(f'Best Method: {best_method}\nAccuracy: {best_accuracy:.2f}%')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load image and ground truth mask
image_path = '/content/output_images_tetra/image_0.png'
mask_path = '/content/output_masks_tetra/image_0_object_0.png'

image = cv2.imread(image_path)
mask_gt = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
mask_gt = cv2.bitwise_not(mask_gt)

# Convert to grayscale
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Apply Gaussian Blur to remove noise
blurred = cv2.GaussianBlur(gray, (5, 5), 0)

# Apply Otsu's thresholding
_, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

# ---------------- Morphological Operations ---------------- #

# Hit-or-Fit (Basic Erosion)
kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]], dtype=np.uint8)
hit_or_fit = cv2.erode(binary, kernel, iterations=1)

# Erosion & Edge Detection
eroded = cv2.erode(binary, np.ones((3,3), np.uint8), iterations=1)
edge_detected = binary - eroded

# Opening (Removes noise)
opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))

# Closing (Fills small holes)
closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((3,3), np.uint8))

# ---------------- Grassfire Algorithms for Blob Detection ---------------- #

def recursive_grassfire(matrix, x, y, label):
    """Recursive Grassfire Algorithm to label connected components"""
    if x < 0 or y < 0 or x >= matrix.shape[0] or y >= matrix.shape[1]:
        return
    if matrix[x, y] != 255:  # Not a foreground pixel
        return
    matrix[x, y] = label  # Assign a label
    # Recursively visit neighbors
    recursive_grassfire(matrix, x+1, y, label)
    recursive_grassfire(matrix, x-1, y, label)
    recursive_grassfire(matrix, x, y+1, label)
    recursive_grassfire(matrix, x, y-1, label)

def apply_recursive_grassfire(binary_image):
    """Apply Recursive Grassfire Algorithm"""
    labeled_image = binary_image.copy()
    label = 50  # Start with a non-zero label
    for i in range(labeled_image.shape[0]):
        for j in range(labeled_image.shape[1]):
            if labeled_image[i, j] == 255:  # Unvisited foreground pixel
                recursive_grassfire(labeled_image, i, j, label)
                label += 50  # Increment label for next object
    return labeled_image

def sequential_grassfire(binary_image):
    """Sequential Grassfire Algorithm for blob labeling"""
    labeled_image = np.zeros_like(binary_image)
    label = 1
    for i in range(binary_image.shape[0]):
        for j in range(binary_image.shape[1]):
            if binary_image[i, j] == 255 and labeled_image[i, j] == 0:
                stack = [(i, j)]
                while stack:
                    x, y = stack.pop()
                    if labeled_image[x, y] == 0:  # Assign label
                        labeled_image[x, y] = label
                        # Push neighbors onto stack
                        for dx, dy in [(-1,0), (1,0), (0,-1), (0,1)]:
                            nx, ny = x + dx, y + dy
                            if 0 <= nx < binary_image.shape[0] and 0 <= ny < binary_image.shape[1]:
                                if binary_image[nx, ny] == 255 and labeled_image[nx, ny] == 0:
                                    stack.append((nx, ny))
                label += 1
    return labeled_image

# Apply both Grassfire Algorithms
recursive_result = apply_recursive_grassfire(binary.copy())
sequential_result = sequential_grassfire(binary)

# ---------------- IoU Calculation for Segmentation Accuracy ---------------- #

intersection = np.logical_and(mask_gt, binary)
union = np.logical_or(mask_gt, binary)
iou_score = np.sum(intersection) / np.sum(union)

# ---------------- Display Results ---------------- #

fig, axs = plt.subplots(3, 3, figsize=(12, 12))

axs[0, 0].imshow(image, cmap='gray')
axs[0, 0].set_title("Original Image")

axs[0, 1].imshow(binary, cmap='gray')
axs[0, 1].set_title("Thresholded Image")

axs[0, 2].imshow(hit_or_fit, cmap='gray')
axs[0, 2].set_title("Hit-or-Fit (Erosion)")

axs[1, 0].imshow(edge_detected, cmap='gray')
axs[1, 0].set_title("Erosion & Edge Detection")

axs[1, 1].imshow(opening, cmap='gray')
axs[1, 1].set_title("Opening (Noise Removal)")

axs[1, 2].imshow(closing, cmap='gray')
axs[1, 2].set_title("Closing (Hole Filling)")

axs[2, 0].imshow(recursive_result, cmap='jet')
axs[2, 0].set_title("Recursive Grassfire Blobs")

axs[2, 1].imshow(sequential_result, cmap='jet')
axs[2, 1].set_title("Sequential Grassfire Blobs")

axs[2, 2].text(0.5, 0.5, f"IoU Score: {iou_score:.4f}", fontsize=14, ha='center')
axs[2, 2].axis("off")

plt.tight_layout()
plt.show()

